{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03f61113-edb8-4a22-8ad1-d6c8410fd349",
   "metadata": {},
   "source": [
    "# Life cycle of machine learning project\n",
    "###  data analysis\n",
    "- Understand the project statement\n",
    "- Data Collection\n",
    "- Data check to perform \n",
    "- Exploraroty data analysis\n",
    "\n",
    "### model development\n",
    "- Understand the project statement\n",
    "- Data Collection\n",
    "- Data Cleaning\n",
    "- feature engineering\n",
    "- Data preprocessing\n",
    "- Model training\n",
    "- Choose the best model\n",
    "### model deployment\n",
    "- structure the code in modular programming\n",
    "- configure the docker image to make the code deployable\n",
    "- deploy the model in aws"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a172c3de-66ec-415e-882a-f519dd88319f",
   "metadata": {},
   "source": [
    "### libraries necesary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "12dff766-b4bf-46e6-a2a3-822f07f052ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data extraction\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "#data cleaning\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "#data preprocesing \n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#models\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "#models metrics\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0dc0401-bf7d-4f13-a769-33e8280ee10c",
   "metadata": {},
   "source": [
    "### 1.0 problem statement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504d436b-7734-478d-95ba-451467108180",
   "metadata": {},
   "source": [
    "Company X specializes in buying second-hand cars. To determine which car to purchase, an employee of the company must examine the carâ€™s features, such as the number of passengers it can carry, the number of doors it has, among others. Based on various characteristics, the employee determines whether it is acceptable to buy the car by assigning one of the following options: evaluation level (unacceptable, acceptable, good, very good). The company wants to make this process more automated, and you have been given access to the database, so your task is to create a program that, based on the car's characteristics, \n",
    "automatically determines if it is acceptable to buy or not\n",
    "<br>\n",
    "url: https://www.kaggle.com/datasets/stealthtechnologies/car-evaluation-classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f97c2964-59d5-4cc4-9976-1a365512350b",
   "metadata": {},
   "source": [
    "### 2.0 Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38c7842-3fec-4739-8cec-67932d438b0d",
   "metadata": {},
   "source": [
    "#### 2.1 data extracion from database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f73ee0d1-aea9-4957-96b6-dfe8d7efe49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = \"ODBC+Driver+17+for+SQL+Server\"\n",
    "server_name = \"localhost\"\n",
    "database = \"BDdatasets\"\n",
    "UID = \"sa\"\n",
    "PWD = \"0440\"\n",
    "\n",
    "connection_string = f\"mssql+pyodbc://{UID}:{PWD}@{server_name}/{database}?driver={driver}\"\n",
    "\n",
    "engine = create_engine(connection_string)\n",
    "\n",
    "query  = \"Select * FROM CarsBuyClassification\"\n",
    "\n",
    "df = pd.read_sql_query( query,engine )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd56be4-6699-46c2-add9-379dfe2e01c5",
   "metadata": {},
   "source": [
    "#### 2.2 check top 5 records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "479d00eb-8f35-4dbc-a1b5-826a5e4decd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>buying</th>\n",
       "      <th>maint</th>\n",
       "      <th>doors</th>\n",
       "      <th>persons</th>\n",
       "      <th>lug_boot</th>\n",
       "      <th>safety</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>high</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  buying  maint doors persons lug_boot safety  class\n",
       "0  vhigh  vhigh     2       2    small    low  unacc\n",
       "1  vhigh  vhigh     2       2    small    med  unacc\n",
       "2  vhigh  vhigh     2       2    small   high  unacc\n",
       "3  vhigh  vhigh     2       2      med    low  unacc\n",
       "4  vhigh  vhigh     2       2      med    med  unacc"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23625d1-1db7-410b-8a6a-6be764af7a51",
   "metadata": {},
   "source": [
    "#### 2.3 contingency table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f459d161-e3b5-4783-9f36-96115944574c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relation between buying and class\n",
      "class   acc  good  unacc  vgood\n",
      "buying                         \n",
      "high    108     0    324      0\n",
      "low      89    46    258     39\n",
      "med     115    23    268     26\n",
      "vhigh    72     0    360      0\n",
      "\n",
      "relation between maint and class\n",
      "class  acc  good  unacc  vgood\n",
      "maint                         \n",
      "high   105     0    314     13\n",
      "low     92    46    268     26\n",
      "med    115    23    268     26\n",
      "vhigh   72     0    360      0\n",
      "\n",
      "relation between doors and class\n",
      "class  acc  good  unacc  vgood\n",
      "doors                         \n",
      "2       81    15    326     10\n",
      "3       99    18    300     15\n",
      "4      102    18    292     20\n",
      "5more  102    18    292     20\n",
      "\n",
      "relation between persons and class\n",
      "class    acc  good  unacc  vgood\n",
      "persons                         \n",
      "2          0     0    576      0\n",
      "4        198    36    312     30\n",
      "more     186    33    322     35\n",
      "\n",
      "relation between lug_boot and class\n",
      "class     acc  good  unacc  vgood\n",
      "lug_boot                         \n",
      "big       144    24    368     40\n",
      "med       135    24    392     25\n",
      "small     105    21    450      0\n",
      "\n",
      "relation between safety and class\n",
      "class   acc  good  unacc  vgood\n",
      "safety                         \n",
      "high    204    30    277     65\n",
      "low       0     0    576      0\n",
      "med     180    39    357      0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for column in df.columns:\n",
    "    if column != \"class\":\n",
    "        contingency_table = pd.crosstab(df[column] , df[\"class\"])\n",
    "        print(f\"relation between {column} and class\")\n",
    "        print(contingency_table)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f996814-a870-475a-8f30-034bb0d6dc91",
   "metadata": {},
   "source": [
    "#### 2.4 check if there are nulls values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1424a177-5231-4d28-96f6-d412feb07c80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "buying      0\n",
       "maint       0\n",
       "doors       0\n",
       "persons     0\n",
       "lug_boot    0\n",
       "safety      0\n",
       "class       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c41590e-387a-42bf-89a1-6728077bd752",
   "metadata": {},
   "source": [
    "### 3.0 Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6bf857-dc2a-45eb-99c3-d87aec0726da",
   "metadata": {},
   "source": [
    "#### 3.1 setting numerical and categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d53edce1-8b36-4baa-93f2-179600973298",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from the eda we know that all features are categorical\n",
    "label = [\"class\"]\n",
    "categorical_columns = [column for column in df.columns if column not in label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "0ea79f78-e45b-46d3-a215-a18d589cd9a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['buying', 'maint', 'doors', 'persons', 'lug_boot', 'safety']"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8461a3-e17a-471a-92a0-bd120c2a4fd1",
   "metadata": {},
   "source": [
    "#### 3.2 getting the uniques values for each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1b204517-40f6-4284-aaf0-795d206215cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " buying\n",
      "['vhigh' 'high' 'med' 'low']\n",
      " maint\n",
      "['vhigh' 'high' 'med' 'low']\n",
      " doors\n",
      "['2' '3' '4' '5more']\n",
      " persons\n",
      "['2' '4' 'more']\n",
      " lug_boot\n",
      "['small' 'med' 'big']\n",
      " safety\n",
      "['low' 'med' 'high']\n",
      " class\n",
      "['unacc' 'acc' 'vgood' 'good']\n"
     ]
    }
   ],
   "source": [
    "for column in df.columns:\n",
    "    print(f\" {column}\")\n",
    "    print(df[column].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2075d139-8847-4709-bf89-0afb38dbda25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the order is setting in this way because, the firt category is assinged 0, de second 1, ans so on\n",
    "features_categories = [\n",
    "    [\"low\" , \"med\" , \"high\" ,\"vhigh\"] , # buying\n",
    "    [\"low\" , \"med\" , \"high\" ,\"vhigh\"],     # maint\n",
    "    ['2', '3', '4', '5more'],            # doors\n",
    "    ['2', '4', 'more'],                  # persons\n",
    "    ['small', 'med', 'big'],             # lug_boot\n",
    "    ['low', 'med', 'high']               # safety\n",
    "]\n",
    "label_categories = [['unacc' ,'acc' , 'good']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8abdefc9-3bc5-4db8-9113-e3430e80f295",
   "metadata": {},
   "source": [
    "####  3.2 join the label vgood and good in one categorie "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "53c5c378-2c1e-406f-9465-923f1b9d14a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df[\"class\"] == \"vgood\" , \"class\"] = \"good\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6657b6e5-1f87-4018-a518-08b883275d02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['unacc', 'acc', 'good'], dtype=object)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"class\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0667a9ad-d01d-4b5c-ba5e-4a91553f01ec",
   "metadata": {},
   "source": [
    "#### 3.3 setting X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cf622de8-a373-4256-a4e9-4a330860842d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[categorical_columns]\n",
    "y = df[label]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca83f3b9-2692-4d30-9e90-784ead374dbb",
   "metadata": {},
   "source": [
    "#### 3.4 making the cleaning pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d0f58336-fda7-4e76-893d-a0d50c4d688a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#due to the fact that there is just categorical columns the clearning pipeline is shorter\n",
    "cat_cleaning_pipeline = ColumnTransformer([\n",
    "                            (\"cat_clearning\" , SimpleImputer(strategy = \"most_frequent\") , categorical_columns)\n",
    "                                          ] )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "46543de9-fd52-4f88-9c3d-6a7586960aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cleaned = pd.DataFrame(cat_cleaning_pipeline.fit_transform(X) , columns = categorical_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2887d3b-51cb-4c57-8ee3-060e6ebe19fd",
   "metadata": {},
   "source": [
    "### 4.0 feature engineering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2abbd978-ba0a-45f5-b2bc-d87e54ac0937",
   "metadata": {},
   "outputs": [],
   "source": [
    "####dude the nature of the problem i think that is not posible do feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fab5e0c-bdf1-44c6-a83c-14c18bdf07e8",
   "metadata": {},
   "source": [
    "### 5.0 data preprocesing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf1c85e-4cfd-46c5-9244-708db0faa230",
   "metadata": {},
   "source": [
    "5.1 create the preprocesor pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "956895e9-9e60-4a03-96cd-3931decb4143",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor_pipeline = ColumnTransformer(\n",
    "    [\n",
    "        (\"ordinal_encoder\" , OrdinalEncoder(categories = features_categories) , categorical_columns)\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "1206dacc-d576-4cac-943d-e3393e906640",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_preprocessed = preprocessor_pipeline.fit_transform(X_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "1cf1127a-bda4-4d8e-935c-8173687e21e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['vhigh' 'vhigh' '2' '2' 'small' 'low']\n",
      "[[3. 3. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "#muestra con un solo ejemplo\n",
    "example = X_cleaned.iloc[0].values\n",
    "\n",
    "print(example)\n",
    "\n",
    "example = pd.DataFrame([example], columns=X_cleaned.columns)\n",
    "\n",
    "print(preprocessor_pipeline.transform(example))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59d0e5a-27cc-4a1e-9e74-e62d397b849a",
   "metadata": {},
   "source": [
    "#### 5.2 preprocess the labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "90db45fa-8b66-4d9e-a80f-dc710be2aeb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_preprocessor = ColumnTransformer([\n",
    "    (\"label_transformer\" , OrdinalEncoder(categories =label_categories ),label  )\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "e5cc738f-f976-415f-8ecc-be00b1f60891",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preprocessed = label_preprocessor.fit_transform(y)[: , 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "4f3d3cdf-b4b2-4f9b-a602-bcaf751b528a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1728,)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_preprocessed.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e27d5b-6181-44dd-9c64-af36d43b9a72",
   "metadata": {},
   "source": [
    "### 5.3 dividing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "5263885f-dd38-4284-a778-78e24ce6ac6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train , X_test , y_train , y_test  = train_test_split( X_preprocessed, y_preprocessed , test_size = 0.2 , random_state = 42 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "98da3342-971c-472b-b5bb-83256df9b4c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.False_"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isnan(X_train).any()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a356659-dba8-4969-9855-3586a6f2cada",
   "metadata": {},
   "source": [
    "### 6.0 Model training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f19fa51-3af4-4f17-8dd2-f0cf4cc37f93",
   "metadata": {},
   "source": [
    "#### 6.1 defining evaluating function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "4a8d966b-1214-44e9-8898-d94a6e413986",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(y_true , y_pred):\n",
    "    accuracy = accuracy_score(y_true , y_pred )\n",
    "    recall = recall_score(y_true , y_pred , average =\"macro\")\n",
    "    precision =precision_score(y_true , y_pred , average =\"macro\")   \n",
    "    f1 = f1_score(y_true , y_pred , average =\"macro\")\n",
    "    average_score = ( accuracy + recall + precision + f1 ) / 4\n",
    "    return  ( accuracy,recall ,precision ,f1 , average_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac0bb48-7d44-4edc-84d5-c4e9d770b1e3",
   "metadata": {},
   "source": [
    "#### 6.2 defining the models and params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "f916b48d-9ff9-4863-87a4-86dcdd16ec37",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"LogisticRegression\": LogisticRegression(),\n",
    "    \"AdaBoostClassifier\": AdaBoostClassifier(),\n",
    "    \"XGBClassifier\": XGBClassifier(),\n",
    "    \"KNeighborsClassifier\": KNeighborsClassifier()\n",
    "}\n",
    "\n",
    "# Definimos los hiperparÃ¡metros para cada modelo\n",
    "models_params = {\n",
    "    \"LogisticRegression\": {\n",
    "        'C': [0.1, 1],\n",
    "        'solver': ['liblinear', 'saga'],  # Agrega solver para compatibilidad\n",
    "        'penalty': ['l1', 'l2'],\n",
    "        'max_iter': [200, 500]\n",
    "    },\n",
    "    \"AdaBoostClassifier\": {\n",
    "        'n_estimators': [50, 100],\n",
    "        'learning_rate': [0.1, 0.5]  ,    \n",
    "        'algorithm': ['SAMME']  \n",
    "    },\n",
    "    \"XGBClassifier\": {\n",
    "        'n_estimators': [50, 100],\n",
    "        'learning_rate': [0.1, 0.2],\n",
    "        'max_depth': [5, 7]\n",
    "    },\n",
    "    \"KNeighborsClassifier\": {\n",
    "        'n_neighbors': [3, 5, 7 , 9 , 12],       # NÃºmero de vecinos\n",
    "        'weights': ['uniform', 'distance'],  # Peso de los puntos\n",
    "        'metric': ['euclidean', ] # MÃ©trica de distancia\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71acf947-0cd5-4801-aac3-fa745f815273",
   "metadata": {},
   "source": [
    "#### 6.3 training the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "bb84ba29-386a-440f-90e6-8df422f89a79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models perfomance\n",
      "model_name LogisticRegression\n",
      "perfomance in training set\n",
      "train_accuracy: 0.8393632416787264\n",
      "train_recall : 0.7366841485753289\n",
      "train_precision : 0.7783227952725819\n",
      "train_f1 : 0.754931758320696\n",
      "train_average_score : 0.7773254859618333\n",
      "----------------------------------------\n",
      "perfomance in test set\n",
      "test_accuracy : 0.8236994219653179\n",
      "test_recall : 0.7623338338155051\n",
      "test_precision : 0.7795532969446013\n",
      "test_f1 : 0.7662953555784426\n",
      "test_average_score : 0.7829704770759667\n",
      "========================================\n",
      "\n",
      "\n",
      "\n",
      "model_name AdaBoostClassifier\n",
      "perfomance in training set\n",
      "train_accuracy: 0.85383502170767\n",
      "train_recall : 0.7130767462755175\n",
      "train_precision : 0.8636545782408335\n",
      "train_f1 : 0.7086640988106075\n",
      "train_average_score : 0.7848076112586571\n",
      "----------------------------------------\n",
      "perfomance in test set\n",
      "test_accuracy : 0.8901734104046243\n",
      "test_recall : 0.7442615446588787\n",
      "test_precision : 0.8948294914295993\n",
      "test_f1 : 0.7521416899162622\n",
      "test_average_score : 0.8203515341023412\n",
      "========================================\n",
      "\n",
      "\n",
      "\n",
      "model_name XGBClassifier\n",
      "perfomance in training set\n",
      "train_accuracy: 1.0\n",
      "train_recall : 1.0\n",
      "train_precision : 1.0\n",
      "train_f1 : 1.0\n",
      "train_average_score : 1.0\n",
      "----------------------------------------\n",
      "perfomance in test set\n",
      "test_accuracy : 0.9826589595375722\n",
      "test_recall : 0.9680149168100977\n",
      "test_precision : 0.9436972573839663\n",
      "test_f1 : 0.9543209876543209\n",
      "test_average_score : 0.9621730303464893\n",
      "========================================\n",
      "\n",
      "\n",
      "\n",
      "model_name KNeighborsClassifier\n",
      "perfomance in training set\n",
      "train_accuracy: 1.0\n",
      "train_recall : 1.0\n",
      "train_precision : 1.0\n",
      "train_f1 : 1.0\n",
      "train_average_score : 1.0\n",
      "----------------------------------------\n",
      "perfomance in test set\n",
      "test_accuracy : 0.9421965317919075\n",
      "test_recall : 0.8960126219162364\n",
      "test_precision : 0.9137573588374504\n",
      "test_f1 : 0.901864584196218\n",
      "test_average_score : 0.913457774185453\n",
      "========================================\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_and_score = []\n",
    "print(\"models perfomance\")\n",
    "\n",
    "for model_name , model in models.items():\n",
    "    params = models_params[model_name]\n",
    "    gs = GridSearchCV(model , params , cv = 3)\n",
    "    gs.fit(X_train , y_train)\n",
    "\n",
    "    model.set_params(**gs.best_params_)\n",
    "\n",
    "    model.fit(X_train , y_train)\n",
    "\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    train_accuracy , train_recall , train_precision , train_f1 , train_average_score = evaluate_model(y_train , y_train_pred)\n",
    "    test_accuracy , test_recall , test_precision , test_f1 , test_average_score = evaluate_model(y_test , y_test_pred)\n",
    "\n",
    "    print(f\"model_name {model_name}\")\n",
    "    print(f\"perfomance in training set\")\n",
    "    print(f\"train_accuracy: {train_accuracy}\")\n",
    "    print(f\"train_recall : {train_recall}\")\n",
    "    print(f\"train_precision : {train_precision}\")\n",
    "    print(f\"train_f1 : {train_f1}\")\n",
    "    print(f\"train_average_score : {train_average_score}\")\n",
    "    print(\"-\" * 40)\n",
    "    print(f\"perfomance in test set\")\n",
    "    print(f\"test_accuracy : {test_accuracy}\")\n",
    "    print(f\"test_recall : {test_recall}\")\n",
    "    print(f\"test_precision : {test_precision}\")\n",
    "    print(f\"test_f1 : {test_f1}\")\n",
    "    print(f\"test_average_score : {test_average_score}\")\n",
    "    print(\"=\"*40)\n",
    "    print(\"\\n\\n\")\n",
    "    model_and_score.append(\n",
    "        {\n",
    "         \"model_name\": model_name,\n",
    "         \"test_accuracy\":test_accuracy ,\n",
    "         \"test_recall\":test_recall ,\n",
    "         \"test_precision\":test_precision ,\n",
    "         \"test_f1\":test_f1 ,\n",
    "         \"test_average_score\":test_average_score \n",
    "        }\n",
    "    )\n",
    "model_and_score_df = pd.DataFrame(model_and_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868cd264-66c7-456e-861c-a65a1e66925d",
   "metadata": {},
   "source": [
    "#### 7.0 choose de best model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138ecc4c-1174-4af7-a7bf-98ce14ee81f2",
   "metadata": {},
   "source": [
    "#### 7.1 chosing by score average "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "3f651a28-bf0d-4454-ab92-f1047203f26f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>test_average_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.982659</td>\n",
       "      <td>0.968015</td>\n",
       "      <td>0.943697</td>\n",
       "      <td>0.954321</td>\n",
       "      <td>0.962173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.942197</td>\n",
       "      <td>0.896013</td>\n",
       "      <td>0.913757</td>\n",
       "      <td>0.901865</td>\n",
       "      <td>0.913458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>0.890173</td>\n",
       "      <td>0.744262</td>\n",
       "      <td>0.894829</td>\n",
       "      <td>0.752142</td>\n",
       "      <td>0.820352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.823699</td>\n",
       "      <td>0.762334</td>\n",
       "      <td>0.779553</td>\n",
       "      <td>0.766295</td>\n",
       "      <td>0.782970</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             model_name  test_accuracy  test_recall  test_precision   test_f1  \\\n",
       "2         XGBClassifier       0.982659     0.968015        0.943697  0.954321   \n",
       "3  KNeighborsClassifier       0.942197     0.896013        0.913757  0.901865   \n",
       "1    AdaBoostClassifier       0.890173     0.744262        0.894829  0.752142   \n",
       "0    LogisticRegression       0.823699     0.762334        0.779553  0.766295   \n",
       "\n",
       "   test_average_score  \n",
       "2            0.962173  \n",
       "3            0.913458  \n",
       "1            0.820352  \n",
       "0            0.782970  "
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_and_score_df.sort_values(by = \"test_average_score\" , ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cbe57c2-53ba-432b-9c30-a56299e06495",
   "metadata": {},
   "source": [
    "#### conclusion\n",
    "- the best model was XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5803f7fe-ae43-4849-9a2c-94929d46183b",
   "metadata": {},
   "source": [
    "<h1>END OF MODELING</h1>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
